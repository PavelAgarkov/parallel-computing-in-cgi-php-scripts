Запуск мультизадачной обработки во время обработки запроса на сервере.
Пакет является встраиваемым в основной поток выполнения скрипта, работает только на unix подобных OC.

   Пакет работает с разделяемой памятью unix. Исходя из необходимого количества воркеров и необходимой памяти
для записи данных из воркеров создается набор ресурсов разделяемой памяти unix. Затем открываются дочерние 
процессы(воркеры), в которые передается информация об участке разделяемой памяти для воркера.
   Создаваемый воркер получает ключ от участка разделяемой памяти, имеющий указанный размер. После чего
восстанавливает подключение к памяти с флагом на запись и записывает сериализованные данные. После чего
в основной процесс, по завершению выполнения каждого воркера, передается управление. Затем закрываются открытые
каналы и процессы, читаются данные из всех участков разделяемой памяти,очищается занятая unix разделяемая память.

Файлы:
 - index.php является точкой входа для cgi или cli;
 - job_1.php - воркер(дочерний процесс) запускаемый родительским процессом, как на сервере, так и при вызове
   через php-cli. 


Пакет применим как серверный или консольный скрипт.

Код для запуска в основном процессе.

```php
use src\ProcessesManager;
$Processes =
    ProcessesManager::runParallelJobs(
        array(
            array(
                "jobName" => 'jobs/job_1',
                "numberJobs" => 485,
                "shSizeForOneJob" => 300,
            ),
            array(

            // "jobName" - путь до файла воркера, "numberJobs" - количество воркеров,
            // "shSizeForOneJob" - память в килобайтах выделенная на один воркер,
            // "dataPartitioning" - массив данных необходимых для параллельной обработки
            // если не указан "dataPartitioning" элемент, то в воркер не передаются данные(если воркер один)
            // в элементе под ключом "dataPartitioning" хранится массив, "flagPartitioning" => разделять ли 
            // данные "dataToPartitioning" между воркерами true - разделять, false - не разделять,
            // а передать в каждый воркер общие данные

                "jobName" => 'jobs/job_2',
                "numberJobs" => 5,
                "shSizeForOneJob" => 30000,
                "dataPartitioning" => array(
                    "flagPartitioning" => false,
                    "dataToPartitioning" => [10, 20, 30]
                )
            ),
            array(
                "jobName" => 'jobs/job_4',
                "numberJobs" => 10,
                "shSizeForOneJob" => 300,
                "dataPartitioning" => array(
                    "flagPartitioning" => false,
                    "dataToPartitioning" => ['commit']
                )
            )
        )
    );

// результат работы параллельных воркеров
$output = $Processes->getOutputData();
```

Код воркера jobs/job_1 .
```php
use src\Job;

Job::runJob(
// STDIN
    $argv,
// Замыкание на выполнение
    function (&$Job, $read): array {
        $array = [10];
        foreach (range(0, 9) as $key => $value) {
            $array[] = $value;
        }
        return [$array];
    }
);
```
